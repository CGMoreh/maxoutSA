[
  {
    "objectID": "timeline/timelines.html",
    "href": "timeline/timelines.html",
    "title": "MAXOUT Study Abroad",
    "section": "",
    "text": "The MAXOUT Study Abroad project is envisaged as a longitudinal cross-institutional mixed-methods research project. The target population is all UK undergraduates studying on a Japanese or/and Korean language/studies course that has a compulsory study abroad year or semester as part of the degree.\nIt aims to interview UK undergraduate students on a Japanese or Korean course at three time-points during their university and post-university careers:"
  },
  {
    "objectID": "timeline/timelines.html#project-timeline",
    "href": "timeline/timelines.html#project-timeline",
    "title": "MAXOUT Study Abroad",
    "section": "Project timeline",
    "text": "Project timeline\nThe Pilot phase of the project began in the 2019/2020 academic year, with an online survey distributed between March-May 2020. Unfortunately, due to the Covid-19 pandemic, study abroad travel on all 3-year degrees was put on hold and due to the general uncertainty regarding study abroad, the project was unable to collect data as planned from all the sampled institutions, and the qualitative interview data collection was also put on hold. Most of the data originated from the then home institution of the research team members, and following a transition to 4-year degrees and a better outlook on the future containment of the pandemic, a new cohort (from a single post-1992 university) was surveyed in October 2020, and qualitative interview data on a smaller selected sample of the respondents was also collected.\nThese two cohorts make up the single-institution pilot phase of the project, and in the 2023/2024 academic year Cohort P2 students (the first post-pandemic student cohort to have taken part in study abroad in their third year of studies on a 4-year degree) also returned from study abroad, making possible the first post-SA data collection round.\n\n\n\n\nFig. 1: MAXOUT data collection timeline\n\n\n\nA funding application is made to implement the first cross-institutional first-year (pre-SA) cohort survey (MAXOUT-SA 1.1.1). This will enable the research team to address the body of research questions that aims to investigate the connections between social mobility and international student mobility on a nationally representative sample. The project cross-section for which funding is sought is highlighted in light grey in the chart below."
  },
  {
    "objectID": "timeline/timelines.html#subproject-naming-convention",
    "href": "timeline/timelines.html#subproject-naming-convention",
    "title": "MAXOUT Study Abroad",
    "section": "Subproject naming convention",
    "text": "Subproject naming convention\n\n\n\nFig. 2: Project component naming convention\n\n\n\n\n\nFig. 1: MAXOUT data collection timeline\nFig. 2: Project component naming convention"
  },
  {
    "objectID": "data/maxout2023-prep.html",
    "href": "data/maxout2023-prep.html",
    "title": "Data preparation report",
    "section": "",
    "text": "The raw data files are downloaded from Qualtrics© into a folder called data_raw with their default Qualtrics© names, which includes the survey name plus the date and time of the download. The data is exported from Qualtrics© as SPSS .sav data files with the extra long labels option.\nThe Qualtrics© questionnaire was based on a design codeplan saved in an Excel .xlsx file, which is stored in a folder named study_design. The same folder also contains a spreadsheet with details about the survey participants who also participated in the follow-up qualitative interview phase of the data collection.\nThe data_raw and study_design folders contain the following files:\n\n\npathsizemodifieddata_raw/postSA_YSJ_2023_3+February+2024_21.40.sav7.29M2024-02-03 21:41:12data_raw/preSA_YSJ_2023_12+April+2024_12.08.sav23.44M2024-04-12 12:08:56data_raw/Study Abroad Expectations_September 11, 2023_17.06.sav43.24M2023-09-12 00:09:39data_raw/Study+Abroad+Expectations+–+External_September+11,+2023_17.09.sav23.82M2023-09-12 00:09:19study_design/MAXOUT-SA_Codeplan.xlsx55.82K2024-04-18 16:43:18study_design/MAXOUT-SA_Interviewees.xlsx12.83K2024-04-25 13:21:27Printed on 05 May 2024\n\n\nThe code below sets up functional links to these files in R:\n\n#### File paths ----------------------------------------------------------------------------------\n\n(datafiles    &lt;- list.files(\"data_raw\", pattern = \"\\\\.sav\"))          # List `.sav` files\n(designfiles  &lt;- list.files(\"study_design\", pattern = \"\\\\.xlsx\"))     # List `.xlsx` files\n\n# (interviewees &lt;- list.files(\"data_qualitative\", pattern = \"\\\\.xlsx\")) # List `.xlsx` files\n\n## 2020 pre-SA\npreSA20_ysj_path   &lt;- file.path(\"data_raw\", grep(\"Study Abroad Expectations\", datafiles, value = TRUE))     # 2020 YSJ student data\npreSA20_ext_path   &lt;- file.path(\"data_raw\", grep(\"External\", datafiles, value = TRUE))                      # 2020 Non-YSJ student data\n\n## 2023 pre-SA\npreSA23_ysj_path   &lt;- file.path(\"data_raw\", grep(\"preSA_YSJ_2023\", datafiles, value = TRUE))                # 2023 YSJ pre-SA data\n\n## 2023 post-SA\npostSA23_ysj_path  &lt;- file.path(\"data_raw\", grep(\"postSA_YSJ_2023\", datafiles, value = TRUE))               # 2023 YSJ post-SA data\n\n## Design\ncodeplan_path      &lt;- file.path(\"study_design\", grep(\"Codeplan\", designfiles, value = TRUE))                # Excel survey codebook\ninterviewees_path  &lt;- file.path(\"study_design\", grep(\"Interviewees\", designfiles, value = TRUE))            # Excel list of interviewees"
  },
  {
    "objectID": "data/maxout2023-prep.html#questionnairevariable-differences",
    "href": "data/maxout2023-prep.html#questionnairevariable-differences",
    "title": "Data preparation report",
    "section": "Questionnaire/variable differences",
    "text": "Questionnaire/variable differences\nThe 2020 pilot data collection consists of a YSJ and an external dataset. The difference between the two questionnaires was a single item that asked YSJ respondents whether they would also be interested in participating in a qualitative interview study. Qualitative data was not collected from external respondents:\n\n\nIn YSJ but not in External data:\n[1] \"ysj_interview\"\n[1] \"Accept to participate in an interview\"\n\nThe position of the variables in the dataset is:\n[1] 303\n\n\nThe 2023 pre-SA survey had several differences compared to the 2020 questionnaire:\n\n\n\n\n\n\n\n2020\n2023\n\n\n\n\nIn which academic year do you expect to go on a Study Abroad year?\n\n2020/2021\n2021/2022\n2022/2023\n2023/2024\n\nIn which year do you expect to go on a Study Abroad year/semester?\n\n2nd year\n3rd year\n\n\n\nWho do you expect to socialize with most while on Study Abroad?\n\n“Mainly with people/colleagues from JP/KO”\n“Mainly with friends/colleagues from my UK university”\n“Mainly with other foreign students”\n“Mainly with students from English speaking countries”\n“I don’t know”\n\nWho do you expect to socialize with most while on Study Abroad?\n\n“Mainly with people/colleagues from JP/KO”\n“Mainly with friends/colleagues from my UK university”\n“Mainly with foreign students from the UK”\n“Mainly with foreign students from other English speaking countries”\n“Mainly with foreign students from non-English-speaking countries”\n“I don’t know”\n\n\n\n\nBlock of 16 questions on “imagined self” was not asked\n\n\n\nThe email question asked for “university email address” specifically\n\n\n\nThe sayr and expect_socialise variables from 2023 were given the _23 suffix to their variable names (in the Codeplan document)."
  },
  {
    "objectID": "data/maxout2023-prep.html#data-import",
    "href": "data/maxout2023-prep.html#data-import",
    "title": "Data preparation report",
    "section": "Data import",
    "text": "Data import\nThe code below imports into R the pre-SA data (.sav files), the variable information (names, labels) from the codeplan document (survey_design/SA_codeplan.xlsx), and information about which respondents also participated in qualitative follow-up interviews (data_qualitative/MAXOUT-SA-Interviewees.xlsx):\n\n#### Import from raw ----------------------------------------------------------------------------------------\n\n## Pre-SA Codeplan\ncodeplan_pre &lt;- read_excel(codeplan_path, sheet = \"preSAvars\")\n\n## Interviewees\ninterviewees &lt;- read_excel(interviewees_path) |&gt; data_select(c(\"Random_ID\", \"interviewed_preSA\", \"interviewed_postSA\"))\n\n## 2020 pre-SA YSJ\npreSA20_ysj &lt;- read_spss(preSA20_ysj_path)                                          # Import from spss\nnames(preSA20_ysj) &lt;- codeplan_pre$varname_pre20                                    # Assign variable names\nsjlabelled::set_label(preSA20_ysj) &lt;- codeplan_pre$varlabel_pre20                   # Assign variable labels\n\n## 2020 pre-SA External\npreSA20_ext &lt;- read_spss(preSA20_ext_path)\nnames(preSA20_ext) &lt;- codeplan_pre$varname_pre20[-303]                              # Assign variable names removing YSJ-specific var\nsjlabelled::set_label(preSA20_ext) &lt;- codeplan_pre$varlabel_pre20[-303]             # Assign variable labels removing YSJ-specific var\n\n## 2023 pre-SA YSJ\npreSA23_ysj &lt;- read_spss(preSA23_ysj_path)\nnames(preSA23_ysj) &lt;- na.omit(codeplan_pre$varname_pre23)                           # Assign variable names\nsjlabelled::set_label(preSA23_ysj) &lt;- na.omit(codeplan_pre$varlabel_pre23)          # Assign variable labels"
  },
  {
    "objectID": "data/maxout2023-prep.html#data-management-variables",
    "href": "data/maxout2023-prep.html#data-management-variables",
    "title": "Data preparation report",
    "section": "Data management variables",
    "text": "Data management variables\nBefore merging the datasets, we create an additional cohort column which records the academic year of the pre-SA data collection. The survey for the YSJ study had been kept open for several months, spanning the second semester of the 2019/2020 academic year and the first semester of the 2020/2021 AY, and therefore the preSA20_ysj dataset contains responses from two student cohorts (2019/2020 and 2020/2021). Data for the preSA20_ext dataset should only contain responses from the 2019/2020 student cohort due to the outbreak of the Covid-19 pandemic, which interfered with the data collection since international travel - and Study Abroad years - were put on hold. However, there is one response that was submitted in March 2021. This response will be removed from the dataset:\n\n#### Create `cohort` column ------------------------------------------------------------------------------------\n\npreSA20_ysj &lt;- preSA20_ysj |&gt; \n  mutate(cohort = case_when(StartDate &lt; as.POSIXct(\"2020-09-01\") ~ \"2019/2020\",\n                            StartDate &gt;= as.POSIXct(\"2020-09-01\") ~ \"2020/2021\"))\n\npreSA20_ext &lt;- preSA20_ext |&gt; \n  mutate(cohort = \"2019/2020\") |&gt; \n  dplyr::filter(StartDate &lt; as.POSIXct(\"2020-09-01\"))  # remove response dating \"2021-03-20 16:11:51\"\n\npreSA23_ysj &lt;- preSA23_ysj |&gt; \n  mutate(cohort = \"2023/2024\")"
  },
  {
    "objectID": "data/maxout2023-prep.html#merging-the-pre-sa-datasets",
    "href": "data/maxout2023-prep.html#merging-the-pre-sa-datasets",
    "title": "Data preparation report",
    "section": "Merging the pre-SA datasets",
    "text": "Merging the pre-SA datasets\nMerging the three datasets should therefore have ncol(preSA20_ysj) + 3 = 312 variables.\nThe code below merges the datasets and checks its dimensions:\n\n#### Merge all pre-SA datasets from 2020 and 2023 ---------------------------------------------------------------\npreSA &lt;- sjmisc::add_rows(preSA20_ysj,   # `this`sjmisc::add_rows` keeps `label` attribute but not other non-relevant attributes\n                          preSA20_ext,    ## `dplyr::bind_rows` removes the variable label attributes\n                          preSA23_ysj)    ## `datawizard::data_merge` keeps all SPSS-specific attributes (`display_width`, `format.spss`)\n\n### Check dimensions of merged dataframe                                                                      \ndim(preSA)\n\n[1] 243 312\n\n\n\n\nNumber of columns as expected: TRUE"
  },
  {
    "objectID": "data/maxout2023-prep.html#replacing-piped-text",
    "href": "data/maxout2023-prep.html#replacing-piped-text",
    "title": "Data preparation report",
    "section": "Replacing piped text",
    "text": "Replacing piped text\nThe Qualtrics© questionnaire included piped text for Japanese and Korean language students, and these appear with non-human-readable characters in the variable and value labels, so we replace these characters with the phrase “JP/KO”:\n\n#### Replace shortcodes for \"Japanese\" and \"Korean\" -----------------------------------------------------\n\n## Get all value labels as list\nlabs &lt;- sjlabelled::get_labels(preSA)\n\n## Change all the values labels in all the variables in list\nlabs &lt;- lapply(labs, function(x) str_replace_all(x,\n                                                 '\\\\$[^\\\\}]*\\\\}',\n                                                 'JP/KO'))\n\n## Apply changed labels to dataset; keep labels as attribute (don't do `as_label(as.numeric)` beforehand)\npreSA &lt;- sjlabelled::set_labels(preSA, labels = labs, force.labels = TRUE)               \n\nFor example, looking at the A1_comjpko variable before and after the change:\n\n\n\n\n\n\n\n\nSpeaks with JP/KO friends in JP/KO (A1_comjpko)\n\n\nValue\nLabel\nN\nRaw %\nValid %\nCum. %\n\n\n\n\n1\n${lm://Field/1}\n38\n15.64\n100\n100\n\n\n&lt;NA&gt;\n&lt;NA&gt;\n205\n84.36\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeaks with JP/KO friends in JP/KO (A1_comjpko)\n\n\nValue\nLabel\nN\nRaw %\nValid %\nCum. %\n\n\n\n\n1\nJP/KO\n38\n15.64\n100\n100\n\n\n&lt;NA&gt;\n&lt;NA&gt;\n205\n84.36\n&lt;NA&gt;\n&lt;NA&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n#### Replace shortcodes for \"Japanese\" and \"Korean\" -----------------------------------------------------\n\n## Get all value labels as list\nlabs &lt;- sjlabelled::get_labels(preSA)\n\n## Change all the values labels in all the variables in list\nlabs &lt;- lapply(labs, function(x) str_replace_all(x,                             \n                                                 '\\\\$[^\\\\}]*\\\\}', \n                                                 \"JP/KO\"))\n\n## Apply changed labels to dataset; keep labels as attribute (don't do `as_label(as.numeric)` beforehand)\npreSA &lt;- sjlabelled::set_labels(preSA, labels = labs, force.labels = TRUE)"
  },
  {
    "objectID": "data/maxout2023-prep.html#converting-categorical-variables",
    "href": "data/maxout2023-prep.html#converting-categorical-variables",
    "title": "Data preparation report",
    "section": "Converting categorical variables",
    "text": "Converting categorical variables\nWe convert the values of all labelled factor (categorical) variables to their labels, so that later we can manipulate the values directly as text.\n\n#### Convert labelled factor variables ------------------------------\n\n## This keeps the unused labels as well\npreSA &lt;- preSA |&gt; \n    mutate(across(where(is.factor), sjlabelled::as_numeric),\n           across(everything(), sjlabelled::as_label))\n\n## This keeps only the labels of categories that had valid responses\n# preSA_alt &lt;- preSA |&gt; \n#     mutate(across(where(is.factor), labels_to_levels))"
  },
  {
    "objectID": "data/maxout2023-prep.html#combining-japanese-and-korean-versions-of-variables",
    "href": "data/maxout2023-prep.html#combining-japanese-and-korean-versions-of-variables",
    "title": "Data preparation report",
    "section": "Combining Japanese and Korean versions of variables",
    "text": "Combining Japanese and Korean versions of variables\nThe survey questions were broken down by language studied (Japanese/Korean), and we have duplicate variables coding the same question (prefixed with “A1_” for Japanese and “A2_” for Korean). With the code below we combine these variables:\n\n#### Unify variables split by language ---------------------------------------------------------\n\nkorean &lt;- preSA |&gt; \n  dplyr::filter(language == \"Korean\") |&gt;\n  select(!starts_with(\"A1\")) |&gt; \n  rename_with(stringr::str_replace,\n              pattern = \"A2_\", replacement = \"\",\n              matches(\"A2_\"))\n\n\njapanese &lt;- preSA |&gt; \n  dplyr::filter(language == \"Japanese\") |&gt;\n  select(!starts_with(\"A2\")) |&gt; \n  rename_with(stringr::str_replace,\n              pattern = \"A1_\", replacement = \"\",\n              matches(\"A1_\"))\n\nmissing &lt;- preSA |&gt;\n  dplyr::filter(is.na(language)) |&gt;                   # 13 missing answers to language\n  datawizard::remove_empty_columns()                  # remove all empty columns\n\npreSA &lt;- sjmisc::add_rows(japanese, korean, missing)"
  },
  {
    "objectID": "data/maxout2023-prep.html#removing-incomplete-responses",
    "href": "data/maxout2023-prep.html#removing-incomplete-responses",
    "title": "Data preparation report",
    "section": "Removing incomplete responses",
    "text": "Removing incomplete responses\nThere were 13 responses with missing data on language. Since the language studied was a core compulsory-answer item, these 13 cases were also unfinished responses. Of the 243 responses in the pre-SA dataset 183 have been finished and submitted. We keep only finished cases:\n\n#### Keep only completed and submitted responses ---------------------------\n\npreSA &lt;- preSA |&gt;\n  dplyr::filter(Finished == \"True\")"
  },
  {
    "objectID": "data/maxout2023-prep.html#removing-duplicates",
    "href": "data/maxout2023-prep.html#removing-duplicates",
    "title": "Data preparation report",
    "section": "Removing duplicates",
    "text": "Removing duplicates\nE-mail addresses were requested primarily for the purposes of contacting students who opted in for participation in a follow-up qualitative interview and/or future (post-SA) rounds of data collection, as well as for contacting the winner of the randomly selected participation prize. Respondent e-mail addresses and IP Addresses are also helpful for identifying any data reliability issues, such as duplicate responses (n.b. the IPAddress collected by Qualtrics© is “external”, so those connecting to the same network will share an IP). We find four email addresses with duplicate responses, and we will keep the earlier responses. The reason for this choice is that the information from the later responses could be contaminated by having previously completed the survey already (practice effects). Incidentally, the earlier responses also have fewer missing answers (albeit marginally, a difference of one in two cases).\nThe code below checks duplicates and removes them (suppressing the output for reasons of anonymity):\n\n#### Identify case duplicates (by email) -------------------------------------------------------\n\npreSA |&gt; \n  mutate(dupe = duplicated(preSA$email)) |&gt; \n  janitor::get_dupes(email) |&gt; \n  select(email, IPAddress, dupe_count, dupe, Random_ID, StartDate) |&gt; \n  datawizard::data_to_wide(id_cols = c(\"email\", \"dupe_count\"), names_from = \"dupe\", values_from = \"Random_ID\")\n\n# or\npreSA |&gt; \n  mutate(duplicate = duplicated(preSA$email)) |&gt; \n  data_duplicated(select = \"email\") |&gt; \n  dplyr::add_count(email, name = \"count_duplicates\") |&gt; \n  data_select(c(\"email\", \"IPAddress\", \"count_duplicates\", \"duplicate\", \"Random_ID\", \"StartDate\", \"count_na\"))\n\n## Counting IPAddress is less useful due to shared addresses at campus/dormitory\npreSA |&gt; \n  janitor::get_dupes(IPAddress) |&gt; \n  select(email, IPAddress, dupe_count, Random_ID, StartDate)\n\n\n#### Identify case duplicates (by email) -------------------------------------------------------\n\npreSA |&gt; \n  mutate(dupe = duplicated(preSA$email)) |&gt; \n  janitor::get_dupes(email) |&gt; \n  select(email, IPAddress, dupe_count, dupe, Random_ID, StartDate) |&gt; \n  datawizard::data_to_wide(id_cols = c(\"email\", \"dupe_count\"), names_from = \"dupe\", values_from = \"Random_ID\") |&gt; \n  datawizard::data_rename(c(\"dupe_count\", \"FALSE\", \"TRUE\"), c(\"No. of duplicate emails\", \"ID_first\", \"ID_second\")) |&gt; \n  select(!email) |&gt; \n  tinytable::tt()\n\n \n\n  \n    \n    \n    tinytable_5xutzzj41kmv00oisxh8\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                No. of duplicate emails\n                ID_first\n                ID_second\n              \n        \n        \n        \n                \n                  2\n                  9419 \n                  8436 \n                \n                \n                  2\n                  9514 \n                  8175 \n                \n                \n                  2\n                  95339\n                  70145\n                \n                \n                  2\n                  84953\n                  44422\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n#### Will delete the later responses (incidentally, these also have fewer NAs) -----------------\n`%not_in%` = Negate(`%in%`)\n\npreSA &lt;- preSA |&gt; \n  data_filter(Random_ID %not_in% c(\"8436\", \"8175\", \"70145\", \"44422\"))    # keeps original \"rownames\"; `rownames(preSA) &lt;- NULL` to renumber\n\n# or:  \n# preSA &lt;- preSA |&gt; \n#   dplyr::filter(!Random_ID %in% c(\"8436\", \"8175\", \"70145\", \"44422\"))   # renumbers \"rownames\"\n# or:\n# preSA_alt &lt;- data_unique(preSA, select = \"email\", keep = \"first\")      ## Deletes all attributes!!\n\nThis leaves us with 179 responses/cases/rows.\nWe can also check whether any Random_ID numbers have been allocated multiple times (unfortunately, Qualtrics© doesn’t have a system to fine-tune the randomisation of numbers…). We find that the Random_ID number 3591 has been allocated twice. One was allocated to an external participant, so we replace it by adding a suffix consisting of two 0s to it.\n\n#### Identify identical Random_IDs --------------------------------------------------------\npreSA |&gt; \n  janitor::get_dupes(Random_ID) |&gt; \n  select(Random_ID, cohort, uni, language) |&gt; \n  tinytable::tt()\n\n \n\n  \n    \n    \n    tinytable_g7z6oakvb85c6jeybjus\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                Random_ID\n                cohort\n                uni\n                language\n              \n        \n        \n        \n                \n                  3591\n                  2020/2021\n                  York St John University\n                  Japanese\n                \n                \n                  3591\n                  2019/2020\n                  Cardiff University     \n                  Japanese\n                \n        \n      \n    \n\n    \n\n  \n\n\n\n#### Fix identical Random_IDs -------------------------------------------------------------\npreSA$Random_ID[preSA$uni == \"Cardiff University\" & preSA$Random_ID == \"3591\" ] &lt;- \"359100\""
  },
  {
    "objectID": "data/maxout2023-prep.html#variable-selection",
    "href": "data/maxout2023-prep.html#variable-selection",
    "title": "Data preparation report",
    "section": "Variable selection",
    "text": "Variable selection\n\nExport labels\nBefore removing unnecessary variables from the dataset, we can export all the variable and value labels so that we can use them in future survey designs. We use the 2023/2024 cohort data for this purpose, as that will serve as the basis for future data collections (code folded).\n\n\nClick to see code\n#### Export label lists ---------------------------------------------------------------------\n\n### Extract variable names and labels\nvarlabs &lt;- preSA |&gt; \n  dplyr::filter(cohort==\"2023/2024\") |&gt; \n  sjlabelled::get_label() |&gt; \n  as.data.frame() |&gt; \n  rownames_as_column() |&gt; \n  rename(name = 1, labels = 2)\n\n### Extract value labels\nvalues &lt;- preSA |&gt; \n  dplyr::filter(cohort==\"2023/2024\") |&gt; \n  recode_values(select = c(IPAddress:   UserLanguage), \n                recode = list(\"Qualtrics_auto\" = \"min:max\"), default = \"Qualtrics_auto\") |&gt; \n  recode_values(select = c(ends_with(\"_txt\"), postcode, email, Random_ID),\n                recode = list(\"open-ended-text\" = \"min:max\"), default = \"open-ended-text\") |&gt; \n  recode_values(select = c(age, finishedschool),\n                recode = list(\"dropdown-options\" = \"min:max\"), default = \"dropdown-options\") |&gt;\n  sjlabelled::get_labels() |&gt; \n  enframe() |&gt; \n  tidyr::unnest_wider(value, names_sep = \",\")\n\npreSA_survey_labels &lt;- left_join(varlabs, values, by = \"name\") \nrm(varlabs, values)\n\n### Remove unwanted entries\npreSA_survey_labels &lt;- preSA_survey_labels |&gt; column_to_rownames(\"name\")\npreSA_survey_labels[\"sayr\" , ] &lt;- preSA_survey_labels[\"sayr_23\" , ]\npreSA_survey_labels[\"expect_socialise\" , ] &lt;- preSA_survey_labels[\"expect_socialise_23\" , ]\npreSA_survey_labels &lt;- preSA_survey_labels |&gt; rownames_to_column(\"name\")\npreSA_survey_labels &lt;- preSA_survey_labels[-c(186:194) , ]\n\n### Export variable and value label list\ndata_write(preSA_survey_labels, \"study_design/preSA_survey_labels.csv\", na = \"\")  \n\n\n\n\nSelect out sensitive data\nWe can select out variables that contain more sensitive information to store separately from the main analysis dataset:\n\n### Select out meta- and safeguarded variables ---------------------------------------------\n\npreSA_sensitive &lt;- preSA |&gt; \n  select(Status:Progress, Finished:UserLanguage, postcode, followup, ysj_interview, email, Random_ID) \n\n\n\nSelect out textual data\nWe can also select out variables that contain text entered in open-ended survey questions. These were identified with the _txt suffix in the Codeplan. We create and select the most useful variables to keep in the textual dataset:\n\n### Get names of textual variables -----------------------------------------------------------------------------------------------\n\ntext_variables &lt;- str_subset(names(preSA), pattern = \"_txt\")\n\n### Select and create variables to keep in the textual dataset -------------------------------------------------------------------\n\npreSA_textual &lt;- preSA |&gt;\n  # create text variable concatenating all school types attended\n  data_unite(select = contains(\"school_\"), new_column = \"schools_combined\", remove_na = TRUE, append = TRUE, separator = \", \") |&gt; \n  # data_unite() doesn't want to exclude NAs... bug in the code... have to remove manually...\n  data_modify(.at = \"schools_combined\", .modify = function(x) {text_remove(x, \", NA\")}) |&gt; \n  data_modify(.at = \"schools_combined\", .modify = function(x) {text_remove(x, \"NA, \")}) |&gt; \n  # select variables to keep\n  data_select(c(Random_ID, uni, cohort, language, sayr, sayr_23, \n                gender, age, intstudnt, bornuk, pargrad, schools_combined,\n                text_variables))\n\n\n\nRecode textual data\nIt is more useful to keep a numeric version of the textual variables, which records the number of words in the answers provided, rather that the answers themselves. To distinguish between these and the original variables, we add the suffix _nwords to their names:\n\n### Function to count all \"word\" characters, first converting empty strings to NA\nwordcounts &lt;- function(x) {\n  label &lt;- get_label(x)               # save var labels\n  x |&gt; convert_to_na(na = \"\") |&gt;      # convert to NA to avoid 0 values\n       str_count('\\\\w+') |&gt;           # count all \"words\"\n  set_label(label)                    # reassign the saved labels\n  }\n\n#### Recode textual variables to wordcount numeric variables; add suffix to var name -----\npreSA &lt;- preSA |&gt; \n         data_modify(.at = text_variables, .modify = wordcounts) |&gt; \n         data_addsuffix(pattern = \"_nwords\", select = text_variables)\n\n\n\nInsert information on interviewees\nWe add two additional variables recording whether the respondent has also participated in a qualitative in-depth interview at the pre-SA and post-SA stage:\n\npreSA &lt;- data_merge(preSA, interviewees, id = \"Random_ID\")\npreSA_textual &lt;- data_merge(preSA_textual, interviewees, id = \"Random_ID\")\n\n\n\nRemove, add and relocate variables\nFinal variable preparation tasks. We exclude the sensitive data from the dataset, as well as the PIS variable and topic header variables; we add a variable counting the number of missing answers for each respondent; and we reorder variables:\n\n### Remove, add and relocate variables ---------------------------------------------------------\n\npreSA &lt;- preSA |&gt; \n  # remove variables\n  select(!c(StartDate, EndDate, Status, IPAddress, Progress, RecordedDate:UserLanguage, \n            postcode, email, followup, ysj_interview,    \n            Finished, pis,  \n            contains(\"Topics\"))) |&gt;   \n  # add of count missing answers\n  rowwise() |&gt; \n    mutate(missing_answers = sum(is.na(across(everything())))) |&gt; \n  ungroup() |&gt; \n  # relocate\n  relocate(Random_ID, Duration, missing_answers, interviewed_preSA, interviewed_postSA, uni, cohort) |&gt; \n  relocate(sayr_23, .after = sayr) |&gt; \n  relocate(expect_socialise_23, .after = expect_socialise)\n\n\n\nAnalysis dataset check\nThe final analysis dataset contains 179 cases/rows and 172 variables/columns. 143 responses are from York St John University students. There are 2 variables containing only NA values: (proglength_txt_nwords, sib4occ_study_txt_nwords). The minimum number of missing answers across the dataset is 26 and the maximum is 62, with a median of 40:\n\ndata_tabulate(preSA, missing_answers, include_na = FALSE) |&gt; print_html()\n\n\n\n\n\n\n\nmissing_answers (missing_answers) (integer)\n\n\nValue\nN\nRaw %\nValid %\nCumulative %\n\n\n\n\n26\n1\n0.56\n0.56\n0.56\n\n\n30\n2\n1.12\n1.12\n1.68\n\n\n31\n4\n2.23\n2.23\n3.91\n\n\n32\n2\n1.12\n1.12\n5.03\n\n\n33\n4\n2.23\n2.23\n7.26\n\n\n34\n8\n4.47\n4.47\n11.73\n\n\n35\n11\n6.15\n6.15\n17.88\n\n\n36\n11\n6.15\n6.15\n24.02\n\n\n37\n13\n7.26\n7.26\n31.28\n\n\n38\n15\n8.38\n8.38\n39.66\n\n\n39\n14\n7.82\n7.82\n47.49\n\n\n40\n18\n10.06\n10.06\n57.54\n\n\n41\n9\n5.03\n5.03\n62.57\n\n\n42\n5\n2.79\n2.79\n65.36\n\n\n43\n10\n5.59\n5.59\n70.95\n\n\n44\n4\n2.23\n2.23\n73.18\n\n\n45\n1\n0.56\n0.56\n73.74\n\n\n46\n4\n2.23\n2.23\n75.98\n\n\n47\n1\n0.56\n0.56\n76.54\n\n\n48\n5\n2.79\n2.79\n79.33\n\n\n49\n4\n2.23\n2.23\n81.56\n\n\n50\n1\n0.56\n0.56\n82.12\n\n\n51\n4\n2.23\n2.23\n84.36\n\n\n52\n1\n0.56\n0.56\n84.92\n\n\n53\n1\n0.56\n0.56\n85.47\n\n\n54\n6\n3.35\n3.35\n88.83\n\n\n55\n5\n2.79\n2.79\n91.62\n\n\n56\n6\n3.35\n3.35\n94.97\n\n\n57\n1\n0.56\n0.56\n95.53\n\n\n58\n4\n2.23\n2.23\n97.77\n\n\n59\n1\n0.56\n0.56\n98.32\n\n\n60\n2\n1.12\n1.12\n99.44\n\n\n62\n1\n0.56\n0.56\n100.00\n\n\n\ntotal N=179 valid N=179"
  },
  {
    "objectID": "data/maxout2023-prep.html#data-export",
    "href": "data/maxout2023-prep.html#data-export",
    "title": "Data preparation report",
    "section": "Data export",
    "text": "Data export\nWe export the analysis dataset with the name preSA2023 to SPSS .sav format in a new folder data_in. We export the sensitive data to a new folder data_lock. We also export the textual data to an Excel sheet and include variable names, labels and their concatenated version as additional rows to make them more informative as column headers in Excel:\n\n## Export datasets ---------------------------------------------------------------------------------\n\nfs::dir_create(\"data_in\")\ndatawizard::data_write(preSA, \"data_in/preSA2023.sav\")\n\nfs::dir_create(\"data_lock\")\ndatawizard::data_write(preSA_sensitive, \"data_lock/preSA2023_sensitive.sav\")\n\n## Export qualitative dataset ----------------------------------------------------------------------\n\n\n# For this we use a function I wrote that modifies the behaviour of datawizard::data_write() to allow variable labels to be saved as\n# the first row in the exported text file. This is achieved with an additional optional setting `labels_to_row = TRUE`. \n# If `labels_to_row` is not specified, the function does the same as datawizard::data_write()\n\n# Import the function from GitHub Gist\n\ndevtools::source_gist(\"https://gist.github.com/CGMoreh/a706954fb56cf8cc4a1ddc53ac1a4737\", filename = \"my_data_write.R\")\n\ndata_write(preSA_textual, \"data_in/preSA2023_textual.xlsx\", labels_to_row = TRUE)"
  },
  {
    "objectID": "data/maxout2023-prep.html#data-import-1",
    "href": "data/maxout2023-prep.html#data-import-1",
    "title": "Data preparation report",
    "section": "Data import",
    "text": "Data import\nThe code below imports the post-SA data (.sav files) and the variable information (names, labels) from the Codeplan spreadsheet (survey_design/SA_codeplan.xlsx) into R:\n\n#### Import from raw -----------------------------------------------------------------------------------\n\n## Post-SA codeplan\ncodeplan_post &lt;- read_excel(codeplan_path, sheet = \"postSAvars\")\n\n## 2023 post-SA YSJ\npostSA23_ysj &lt;- read_spss(postSA23_ysj_path)\nnames(postSA23_ysj) &lt;- na.omit(codeplan_post$varname_post23)                    # Assign variable names\nsjlabelled::set_label(postSA23_ysj) &lt;- na.omit(codeplan_post$varlabel_post23)   # Assign variable labels\n\nThe raw postSA23_ysj dataset has 34 answers and 117 variables."
  },
  {
    "objectID": "data/maxout2023-prep.html#data-cleansing",
    "href": "data/maxout2023-prep.html#data-cleansing",
    "title": "Data preparation report",
    "section": "Data cleansing",
    "text": "Data cleansing\nWe fix Qualtrics© shortcodes in labels and convert categorical variable types. We keep the 32 completed responses only. We also remove several variables that were reused/pre-filled automatically from the pre-SA survey, keeping only the pre-filled Random_ID variable for merging. One of the pre-filled Random_IDs corresponds to one of the duplicates that were deleted from the pre-SA dataset. We replace this ID with that of the case kept in the analysis for the purpose of merging. We remove sensitive data.\n\n#### Replace shortcodes for \"Japanese\" and \"Korean\" -----------------------------------------------------------\n\nlabs &lt;- sjlabelled::get_labels(postSA23_ysj)\nlabs &lt;- lapply(labs, function(x) str_replace_all(x,                             \n                               '\\\\$[^\\\\}]*\\\\}', \n                               \"JP/KO\"))\n\npostSA23_ysj &lt;- postSA23_ysj |&gt; \n  sjlabelled::set_labels(labels = labs, force.labels = TRUE)  \n\n#### Export label lists ---------------------------------------------------------------------------------------\n\n### Extract variable names and labels\nvarlabs &lt;- postSA23_ysj |&gt; \n  sjlabelled::get_label() |&gt; \n  as.data.frame() |&gt; \n  rownames_as_column() |&gt; \n  rename(name = 1, labels = 2)\n\n### Extract value labels\nvalues &lt;- postSA23_ysj |&gt; \n  recode_values(select = c(IPAddress_post:UserLanguage_post), \n                recode = list(\"Qualtrics-auto\" = \"min:max\"), default = \"Qualtrics-auto\") |&gt; \n  recode_values(select = c(contains(\"_txt\"), pre_course, course, post_email_uni, post_email_personal, Random_ID),\n                recode = list(\"open-ended-text\" = \"min:max\"), default = \"open-ended-text\") |&gt; \n  # recode_values(select = c(age, finishedschool),\n  #               recode = list(\"dropdown-options\" = \"min:max\"), default = \"dropdown-options\") |&gt;\n  sjlabelled::get_labels() |&gt; \n  enframe() |&gt; \n  tidyr::unnest_wider(value, names_sep = \",\")\n\npostSA_survey_labels &lt;- left_join(varlabs, values, by = \"name\") \nrm(varlabs, values)\n\n### Export variable and value label list------------------------------------------------------------------------\ndata_write(postSA_survey_labels, \"study_design/postSA_survey_labels.csv\", na = \"\")\n\n\n\n#### Extract sensitive data ------------------------------------------------------------------------------------\npostSA_sensitive &lt;- postSA23_ysj |&gt;\n  dplyr::select(c(post_qual_1, post_qual_2,                                          # PIS and eligibility vars\n                  post_email_uni, post_aftergrad_followup, post_email_personal,      # Sensitive\n                  Random_ID))\n\n\n#### Select cases and variables --------------------------------------------------------------------------------\npostSA &lt;- postSA23_ysj |&gt; \n  ## Convert labelled factor variables\n  mutate(across(where(is.factor), sjlabelled::as_numeric),\n         across(everything(), sjlabelled::as_label)) |&gt; \n  ## Select valid responses\n  dplyr::filter(Finished_post == \"True\" &\n                post_qual_1 == \"I agree to take part\" &\n                post_qual_2 == \"I have done a full year of study abroad\") |&gt; \n  ## Select useful variables\n  dplyr::select(!c(StartDate_post:Progress_post, Finished_post:UserLanguage_post,    # Qualtrics variables\n                  uni_post, pre_course, course:SAcountry,                            # Prefilled from Pre-SA survey\n                  post_qual_1, post_qual_2,                                          # PIS and eligibility vars\n                  post_email_uni, post_aftergrad_followup, post_email_personal)) |&gt;  # Sensitive\n  # add of count missing answers\n  rowwise() |&gt; \n    mutate(missing_answers_post = sum(is.na(across(everything())))) |&gt; \n  ungroup() |&gt; \n  data_relocate(missing_answers_post)\n\n#### Replace a `Random_ID`\npostSA$Random_ID[postSA$Random_ID == \"8436\" ] &lt;- \"9419\""
  },
  {
    "objectID": "data/maxout2023-prep.html#merging-pre-sa-and-post-sa-data",
    "href": "data/maxout2023-prep.html#merging-pre-sa-and-post-sa-data",
    "title": "Data preparation report",
    "section": "Merging pre-SA and post-SA data",
    "text": "Merging pre-SA and post-SA data\nWe merge thepostSA23_ysj dataset with the responses from the same individuals from the preSA dataset:\n\npostSA &lt;- data_merge(preSA, postSA, join = \"inner\", by = \"Random_ID\")"
  },
  {
    "objectID": "data/maxout2023-prep.html#data-export-1",
    "href": "data/maxout2023-prep.html#data-export-1",
    "title": "Data preparation report",
    "section": "Data export",
    "text": "Data export\nWe export the analysis dataset with the name postSA2023 to SPSS .sav format to the folder data_in, and the sensitive data to the folder data_lock:\n\n## Export datasets ------------------------------------------------------------------------------\n\nfs::dir_create(\"data_in\")\ndatawizard::data_write(postSA, \"data_in/postSA2023.sav\")\n\nfs::dir_create(\"data_lock\")\ndatawizard::data_write(postSA_sensitive, \"data_lock/postSA2023_sensitive.sav\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MAXOUT Study Abroad",
    "section": "",
    "text": "The MAXOUT Study Abroad project is envisaged as a longitudinal cross-institutional mixed-methods research project investigating the socio-cultural mechanisms linking study motivations, career aspirations, expectations and experiences of international mobility, and the differential social mobility potentials of UK university students enrolled on a Japanese or Korean programme containing a compulsory Study Abroad (SA) year.\nThe project’s focus derives from several observations made in connection to recent trends affecting UK higher education. Research on outward student mobility has highlighted the relevance of social class and parental income to university students’ ability and interest to participate in international exchange programmes, which in turn affects international career opportunities and connections (Findlay and King, 2010; King et al., 2011; Lörz et al., 2016). Particularly, student mobility to continental Europe has been declining for over two decades, with interest shifting to more distant and more expensive English-speaking countries such as the USA or Australia (Findlay et al., 2006). This trend has paralleled a decreasing interest in foreign language study and declining recruitment to undergraduate degrees in languages.\nHowever, two languages in particular – Japanese and Korean – have challenged this trend, with the number of undergraduate degree programmes and student numbers in Japanese and Korean seeing major increases in recent years (HESA, 2023b). One reason may be the attraction of the competing pop-cultural influences of these countries, one of the most successful developments in soft-power public diplomacy since the demise of the “Britpop” cultural movement of the 1990s (Hashimoto, 2018; Jang and Paik, 2012; Koma, 2012; Lee, 2009; Sanz and Carbó-Catalan, 2022). Most undergraduate programmes in Japanese and Korean include a compulsory year abroad component, which may represent a further motivating factor for students with fewer resources to travel to these countries outside the formalised framework of a university degree. This compulsory year abroad plays an essential role in shaping social and cultural identities, facilitating intercultural contact and challenging imagined idealisations of the countries visited (Kinginger, 2013; Mitchell et al., 2015).\nHowever, the interactive social mechanisms linking macro-political factors such as soft power competition, language-learning motivations, career and international mobility aspirations, and social mobility, have not yet been comprehensively studied. This project attempts to gain insights into these mechanisms."
  }
]